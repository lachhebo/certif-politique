{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4575a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from app.data_engineering.data_access import read_db\n",
    "from app.utils.multi_column_label_encode import MultiColumnLabelEncoder\n",
    "from app.data_engineering.feature_engineering import FeatureEngineering\n",
    "from app.model import Model\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01255589",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = read_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b042f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1 = datasets['batch1']\n",
    "df_batch2 = datasets['batch2']\n",
    "df_test = datasets['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb1693",
   "metadata": {},
   "source": [
    "## Définition de nos labels et de nos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0573035",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = df_test['vols'].columns.tolist()\n",
    "FEATURES.remove('NIVEAU DE SECURITE')\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = list(set(df_batch1['vols'].columns.tolist()) - set(df_test['vols'].columns.tolist()))\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624765b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1.keys(), df_batch2.keys(), df_test.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c8e6b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la valeur a prédire \n",
    "label = \"RETARD A L'ARRIVEE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_80_20(X, y): \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da892b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_batch1_smaller = pd.concat([df_batch1['vols'], df_batch2['vols']]).tail(1500000)#.head(1200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_batch1_smaller[FEATURES+[label]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_batch1_smaller[FEATURES+[label]].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf97e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_batch1_smaller[FEATURES+[label]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c76611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../certifia/data_cleaning.py\n",
    "class DataCleaning:\n",
    "    def __init__(self, features_columns, label):\n",
    "        self.features_columns = features_columns\n",
    "        self.label = label\n",
    "\n",
    "    def remove_unused_columns(self, df):\n",
    "        if 'NIVEAU DE SECURITE' in df.columns:\n",
    "            df = df.drop(columns=['NIVEAU DE SECURITE'])\n",
    "        return df\n",
    "\n",
    "    def cleaning(self, df):\n",
    "        df = df.dropna(subset=self.features_columns)\n",
    "        if self.label in df.columns:\n",
    "            df = df.dropna(subset=[self.label])\n",
    "        return df\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        df = self.cleaning(df)\n",
    "        df = self.remove_unused_columns(df)\n",
    "        df.loc[:, 'DATE'] = pd.to_datetime(df['DATE'])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = DataCleaning(features_columns=FEATURES, label=label)\n",
    "cleaned_vol = cleaning.transform(vol_batch1_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_vol[FEATURES]\n",
    "y = cleaned_vol[label]#.apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_80_20(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2142f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../certifia/feature_engineering.py\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from certifia.utils.multi_column_label_encode import MultiColumnLabelEncoder\n",
    "\n",
    "\n",
    "class FeatureEngineering:\n",
    "    def __init__(self, training_columns=None, columns_to_dummify=None):\n",
    "        self.training_columns = training_columns\n",
    "        self.columns_to_dummify = columns_to_dummify\n",
    "        self.label_encoder = MultiColumnLabelEncoder(columns=self.columns_to_dummify)\n",
    "        self.average_nb_plane_by_day = {}\n",
    "\n",
    "    def get_month(self, df):\n",
    "        return df.apply(lambda x: x.month)\n",
    "\n",
    "    def get_week(self, df):\n",
    "        return df.apply(lambda x: x.week)\n",
    "\n",
    "    def get_hour(self, df):\n",
    "        return df.apply(lambda x: x // 100)\n",
    "\n",
    "    def __get_dict_of_average_plane_by_day(self, df, airport_type: str):\n",
    "        min_date = df['DATE'].min()\n",
    "        max_date = df['DATE'].max()\n",
    "        number_of_days = (max_date - min_date).days + 1\n",
    "        return df[\n",
    "            [airport_type, 'IDENTIFIANT', 'DATE']].groupby([airport_type, 'DATE']).count().reset_index()[\n",
    "            [airport_type, 'IDENTIFIANT']].groupby([airport_type]).sum().apply(\n",
    "            lambda x: x / number_of_days\n",
    "        )['IDENTIFIANT'].to_dict()\n",
    "\n",
    "    def get_average_plane_take_off_or_landing_by_day(self, df, airport_type):\n",
    "        self.average_nb_plane_by_day[airport_type] = self.__get_dict_of_average_plane_by_day(df, airport_type)\n",
    "        return df[airport_type].apply(lambda x: self.average_nb_plane_by_day[airport_type][x])\n",
    "\n",
    "    def apply_average_plane_take_off_or_landing_by_day(self, df, airport_type):\n",
    "        return df[airport_type].apply(\n",
    "            lambda x: self.average_nb_plane_by_day[airport_type][x] if x in self.average_nb_plane_by_day[\n",
    "                airport_type] else 0)\n",
    "\n",
    "    def keep_training_columns(self, X):\n",
    "        if self.training_columns is not None:\n",
    "            return X[self.training_columns]\n",
    "        return X\n",
    "\n",
    "    def fit_transform_dummify_columns(self, X):\n",
    "        if self.columns_to_dummify is not None:\n",
    "            return self.label_encoder.fit_transform(X)\n",
    "        return X\n",
    "\n",
    "    def transform_dummify_columns(self, X):\n",
    "        if self.columns_to_dummify is not None:\n",
    "            return self.label_encoder.transform(X)\n",
    "        return X\n",
    "\n",
    "    def fit(self, dataframe: pd.DataFrame):\n",
    "        X = dataframe.copy()\n",
    "\n",
    "        X.loc[:, 'MOIS'] = self.get_month(X['DATE'])\n",
    "        X.loc[:, 'SEMAINE'] = self.get_week(X['DATE'])\n",
    "        X.loc[:, 'HEURE DEPART PROGRAMME'] = self.get_hour(X['DEPART PROGRAMME'])\n",
    "        X.loc[:, 'HEURE ARRIVEE PROGRAMMEE'] = self.get_hour(X['ARRIVEE PROGRAMMEE'])\n",
    "\n",
    "        X.loc[:, 'NOMBRE DECOLLAGE PAR AEROPORT PAR JOUR'] = self.get_average_plane_take_off_or_landing_by_day(\n",
    "            X, 'AEROPORT DEPART'\n",
    "        )\n",
    "        X.loc[:, 'NOMBRE ATTERRISSAGE PAR AEROPORT PAR JOUR'] = self.get_average_plane_take_off_or_landing_by_day(\n",
    "            X, 'AEROPORT ARRIVEE'\n",
    "        )\n",
    "\n",
    "        X = self.fit_transform_dummify_columns(X)\n",
    "\n",
    "        X = self.keep_training_columns(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def transform(self, dataframe: pd.DataFrame):\n",
    "        X = dataframe.copy()\n",
    "\n",
    "        X.loc[:, 'MOIS'] = self.get_month(X['DATE'])\n",
    "        X.loc[:, 'SEMAINE'] = self.get_week(X['DATE'])\n",
    "        X.loc[:, 'HEURE DEPART PROGRAMME'] = self.get_hour(X['DEPART PROGRAMME'])\n",
    "        X.loc[:, 'HEURE ARRIVEE PROGRAMMEE'] = self.get_hour(X['ARRIVEE PROGRAMMEE'])\n",
    "\n",
    "        X.loc[:, 'NOMBRE DECOLLAGE PAR AEROPORT PAR JOUR'] = self.apply_average_plane_take_off_or_landing_by_day(\n",
    "            X, 'AEROPORT DEPART'\n",
    "        )\n",
    "        X.loc[:, 'NOMBRE ATTERRISSAGE PAR AEROPORT PAR JOUR'] = self.apply_average_plane_take_off_or_landing_by_day(\n",
    "            X, 'AEROPORT ARRIVEE'\n",
    "        )\n",
    "        X = self.transform_dummify_columns(X)\n",
    "\n",
    "        X = self.keep_training_columns(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    # TODO: add test\n",
    "    def save_feature_engineering(self, path=None):\n",
    "        \"\"\"\n",
    "        Save to file in the current working directory\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = \"../data/output/feature_engineering.pkl\"\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    # TODO: add test\n",
    "    def load_feature_engineering(self, path=None):\n",
    "        \"\"\"\n",
    "        Load file in an instance\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = \"../data/output/feature_engineering.pkl\"\n",
    "        with open(path, 'rb') as file:\n",
    "            pickle_fe = pickle.load(file)\n",
    "            self.training_columns = pickle_fe.training_columns\n",
    "            self.columns_to_dummify = pickle_fe.columns_to_dummify\n",
    "            self.label_encoder = pickle_fe.label_encoder\n",
    "            self.average_nb_plane_by_day = pickle_fe.average_nb_plane_by_day\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "313fd2fb",
   "metadata": {},
   "source": [
    "# dummification\n",
    "#X_batch1_dummified = pd.concat([pd.get_dummies(X_batch1['AEROPORT DEPART'], prefix='AEROPORT_DEPART'),\n",
    "#                               pd.get_dummies(X_batch1['AEROPORT ARRIVEE'], prefix='AEROPORT_ARRIVEE')], axis=1)\n",
    "\n",
    "# Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering = FeatureEngineering(\n",
    "        training_columns=[\n",
    "            'CODE AVION',\n",
    "            'AEROPORT DEPART',\n",
    "            'AEROPORT ARRIVEE', \n",
    "            'TEMPS DE DEPLACEMENT A TERRE AU DECOLLAGE',\n",
    "            \"TEMPS DE DEPLACEMENT A TERRE A L'ATTERRISSAGE\",\n",
    "            'TEMPS PROGRAMME',\n",
    "            'DISTANCE',\n",
    "            'COMPAGNIE AERIENNE',\n",
    "            'NOMBRE DE PASSAGERS',\n",
    "            'MOIS',\n",
    "            'SEMAINE',\n",
    "            'HEURE DEPART PROGRAMME',\n",
    "            'HEURE ARRIVEE PROGRAMMEE'\n",
    "        ],\n",
    "        columns_to_dummify=['AEROPORT DEPART','AEROPORT ARRIVEE', 'COMPAGNIE AERIENNE', 'CODE AVION'],\n",
    "    )\n",
    "X_train_engineered = feature_engineering.fit(X_train)\n",
    "X_test_engineered = feature_engineering.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6efd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train_engineered.head())\n",
    "X_train_engineered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_engineered.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd78247",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27accfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from certifia.utils.logger import Logger\n",
    "\n",
    "class Training:\n",
    "    def __init__(self):\n",
    "        self.rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42,n_jobs=-1,verbose=1)\n",
    "        #self.rf_regressor = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1,verbose=1)\n",
    "        #self.rf_regressor = LinearRegression(normalize=True, n_jobs=-1)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        train a random forest regressor with\n",
    "        X being the training columns and\n",
    "        y the label to predict\n",
    "        \"\"\"\n",
    "        self.rf_regressor.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.rf_regressor.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        logger = Logger().logger\n",
    "        logger.info(f'Mean Absolute Error: {metrics.mean_absolute_error(y, y_pred)}')\n",
    "        logger.info(f'Mean Squared Error: {metrics.mean_squared_error(y, y_pred)}')\n",
    "        logger.info(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(y, y_pred))}')\n",
    "        logger.info(f'R2 score: {metrics.r2_score(y, y_pred)}')\n",
    "\n",
    "    # Pour un classif algorithm\n",
    "    def classif_score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        logger = Logger().logger\n",
    "        logger.info(f'Accuracy: {metrics.accuracy_score(y, y_pred)}')\n",
    "        logger.info(f'Recall: {metrics.recall_score(y, y_pred)}')\n",
    "        logger.info(f'Precision: {metrics.precision_score(y, y_pred)}')\n",
    "        logger.info(f'F1_score: {metrics.f1_score(y, y_pred)}')\n",
    "        logger.info(f'ROC AUC: {metrics.roc_auc_score(y, y_pred)}')\n",
    "\n",
    "    def save_model(self, path=None):\n",
    "        \"\"\"\n",
    "        Save to file in the current working directory\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = \"../models/rf_model.pkl\"\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(self.rf_regressor, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Training().fit(X_train_engineered, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d94d0",
   "metadata": {},
   "source": [
    "# Prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_engineered.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf535b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8d094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95816b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c16ca",
   "metadata": {},
   "source": [
    "# Evaluation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test_engineered, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train_engineered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30d5f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.classif_score(X_test_engineered, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f3318",
   "metadata": {},
   "source": [
    "### test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89188d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-5.18241389,  7.36806039, 10.62997097, 28.9174465 , -7.37209897,\n",
       "        6.60642149, -2.29465309, 26.33183661,  5.37269167])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_test = DataCleaning(features_columns=FEATURES, label=label).cleaning(pd.read_csv('../data/vol_test.csv'))\n",
    "X_small_test_engineered = feature_engineering.transform(small_test)\n",
    "y_pred_small_test = model.predict(X_small_test_engineered)\n",
    "y_pred_small_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7414d",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c332e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a559be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 19.34668043224163\n",
      "Mean Squared Error: 1394.8902425946849\n",
      "Root Mean Squared Error: 37.348229443906504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Load from file\n",
    "with open(\"../models/rf_model.pkl\", 'rb') as file:\n",
    "    pickle_model = pickle.load(file)\n",
    "    \n",
    "# Calculate the accuracy score and predict target values\n",
    "score = pickle_model.score(X_test_engineered, y_test)\n",
    "print(\"R2 score: {0:.4f}\".format(score))\n",
    "y_pred = pickle_model.predict(X_test_engineered)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b14031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
